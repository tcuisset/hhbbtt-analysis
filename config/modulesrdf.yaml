# This configuration is used for PreProcess step
# It is common to all analyses: ZZ, ZH x 2

lumifilter:
    name: lumiFilterRDF
    path: Base.Filters.lumiFilter
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year

# filter bbtautau for datasets used as SM signal
bbtautau_sig_bkg:
    name: BBTauTauFilterRDF
    path: Tools.Tools.gen_information
    parameters:
        ProcType: self.dataset.process.get_aux('ProcType', False)
        isSigBBTT: self.dataset.process.get_aux('isSigBBTT', False)
        isBkgBBTT: self.dataset.process.get_aux('isBkgBBTT', False)
        removeZH: self.dataset.process.get_aux('removeZH', False)
        enable_filter: True

gen_jets:
    name: GenJetsRDF
    path: Tools.Tools.gen_information
    parameters:
        isMC: self.dataset.process.isMC and self.dataset.process.isSignal

gen_leptons:
    name: GenLeptonsRDF
    path: Tools.Tools.gen_information
    parameters:
        isMC: self.dataset.process.isMC and self.dataset.process.isSignal

gen_variables:
    name: GenVariablesRDF
    path: Tools.Tools.gen_information
    parameters:
        isMC: self.dataset.process.isMC and self.dataset.process.isSignal


# dystitching:
#     name: DYstitchingEasyRDF
#     path: Tools.Tools.dyreweighting
#     parameters:
#         isDY: self.dataset.process.get_aux('isDY', False)

# set genWeight to one for some bugged LO madgraph datasets (https://twiki.cern.ch/twiki/bin/view/CMS/MCKnownIssues#Different_weights_at_LHE_level_f)
genWeightLOFix:
    name: GenWeightLOFixRDF
    path: Tools.Tools.genWeightLOFix
    parameters:
        isMC: self.dataset.process.isMC
        setGenWeightToOne: self.dataset.get_aux('setGenWeightToOne', False)

metfilter:
    name: MetFilterRDF
    path: Base.Filters.METfilters
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year

# Electron_pt_smear_up/down & Electron_pt_scale_up/down for MC
eleScaleUncertainties:
    name: eleScaleUncertaintiesRDF
    path: Corrections.EGM.eleCorrections
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        isUL: self.dataset.has_tag('ul')
        ispreVFP: self.config.get_aux('ispreVFP', False)

# Computes DeepTau SFs (event weights) and TES (tau energy scale) : *per-object variations*
# don't compute all the uncertainties if we are already applying a systematic (the weight systs are only applied on top of central)
tauSF:
    name: tauSFRDF
    path: Corrections.TAU.tauCorrections
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        isUL: self.dataset.has_tag('ul')
        runPeriod: self.config.runPeriod
        tauId_algo: self.config.tauId_algo
        vsjet_wps: [Medium] # we use also VVVLoose for QCD but no SFs are available (only Loose, Medium, Tight, VTight )
        vsjet_pt_binned_uncertainties_PY: >-
            ["nom"] if systematic else 'all'
        vsjet_dm_binned_uncertainties_PY: >-
            ["nom"] if systematic else 'all'
        vse_wps: [VVLoose]
        vsmu_wps: [VLoose, Tight]
boostedTauES:
    name: boostedTauEnergyScaleRDF
    path: Tools.Tools.dauIdIso
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        runPeriod: self.config.runPeriod


# Trigger & lepton selections. Depends on TES (&electron scale ?)
hhlepton:
    name: HHLeptonRDF
    path: Tools.Tools.HHLepton
    parameters:
        isMC: self.dataset.process.isMC
        doGenCutFlow: self.dataset.process.isSignal
        isV10: self.dataset.has_tag("nanoV10")
        year: self.config.year
        ispreVFP: self.config.get_aux('ispreVFP', False)
        runEra: self.dataset.runEra
        vvvl_vsjet: self.config.deeptau.vsjet.VVVLoose
# for VsEle, we need to use either VVLoose or Tight in order to apply SFs for genuine taus for VsJet discriminant
# so put VVLosse in vl_vse variable (this should be better named...)
        vl_vse: self.config.deeptau.vse.VVLoose
        vvl_vse: self.config.deeptau.vse.VVLoose
        t_vsmu: self.config.deeptau.vsmu.Tight
        vl_vsmu: self.config.deeptau.vsmu.VLoose
        useBoostedTaus: self.dataset.process.isMC or not self.dataset.has_tag("hpsData") # don't forget to change this also in HHLeptonMETCut
        tau_priority: HPS
        boostedTau_VsMu_threshold: 0 # not used
        boostedTau_VsE_threshold: 0 # not used
        boostedTau_VsJet_threshold: self.config.deepboostedtau.vsjet.VVLooseForPreprocess # something very loose here for QCD estimation
        #boostedTau_VsJet_threshold: 0.85 # raw score threshold, as used by Wisconsin analysis (quite loose)
        pairType_filter: not self.dataset.process.isSignal

# TODO maybe we also want to keep the uncorrected tau variables ?
hhleptonVar:
    name: HHLeptonVarRDF
    path: Tools.Tools.HHLepton
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year

############### JME corrections for AK4 jets 
# JEC should be first then JER on top of JEC nominal/variations (https://cms-talk.web.cern.ch/t/jer-and-jec-variation-question/46184/3)
# JEC is already done in NanoAOD normally. So only variations need to be computed
# 2018 MC : GT used 123X_upgrade2018_realistic_v2,  CondDB https://cms-conddb.cern.ch/cmsDbBrowser/list/Prod/gts/123X_upgrade2018_realistic_v2  - JetCorrectionsRecord is JetCorrectorParametersCollection_Summer19UL18_V5_MC_AK4PFchs
# 2016APV MC : JetCorrectorParametersCollection_Summer19UL16APV_V7_MC_AK4PFchs
# (otherwise JEC nominal would need to be computed here)

### JEC
# not specifying jec_sources will lead to the default being picked up which is the reduced set of 11 (names are year-dependent) + "Total".
# *Either* "Total" or the 11 must be used, not all 12 of them !
        # jec_sources: [FlavorQCD, RelativeBal, HF, BBEC1, EC2, Absolute, BBEC1_2018,
            # EC2_2018, Absolute_2018, HF_2018, RelativeSample_2018, Total]

# Computes jec_factor_{jecSource}_up/down which is an array for every jet
jec_factors:
    name: jecProviderRDF
    path: Corrections.JME.jec
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        isUL: self.dataset.has_tag('ul')
        ispreVFP: self.config.get_aux('ispreVFP', False)
        jet_collection: Jet
# Creates Jet_pt_{jecSource}_up/down branches
jec_jet_corrections:
    name: jecVarRDF
    path: Corrections.JME.jec
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC


## JER (only one single uncertainty, fine as long as we don't constrain it)
# Smear jets in MC. Outputs : jet_smear_factor (_up/_down) & jet_pt_resolution
jet_smearing:
    name: jetSmearerRDF
    path: Corrections.JME.smearing
    parameters:
        year: self.config.year
        runPeriod: self.config.runPeriod
        isMC: self.dataset.process.isMC
        isUL: self.dataset.has_tag('ul')
# Create Jet_pt_nom & Jet_mass_nom & Jet_pt_smeared_up/down & Jet_mass_smeared_up/down
jer_jet:
    name: jetVarRDF
    path: Corrections.JME.smearing
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year


#################### MET
# HHJets uses MET for hhbtag, so compute MET before
# TODO boostedTau systematics propagation to MET ???? (probably should deal with overlap with HPS taus ?)
met_shift:
    name: metShifterRDF
    path: Corrections.JME.met
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        met_smear_tag_data: "" # not applied on data anyway, just here as reminder
        met_smear_tag: "tes_electron"
        jet_syst: "" # do not smear MET. Will be overriden for JEC & JER
        propagate_jer_smearing: False # prevent JER variations from being propagated to MET
        propagate_tes: True 
        propagate_electron: True 

# MET XY corrections. Produces MET_smeared_xycorr_pt_{met_syst} & MET_smeared_xycorr_phi_{met_syst}
MET_XYCorrections:
    name: MET_XYCorrections_RDF
    path: Corrections.JME.met
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        runEra: self.dataset.runEra
        ispreVFP: self.config.get_aux('ispreVFP', False)
        met_smear_tag_data: "" # on data  there is no TES or electron S&S 
        met_smear_tag: "tes_electron" # defines the input smear_tag

MET_unclusteredEnergy:
    name: MET_UnclusteredEnergy_RDF
    path: Corrections.JME.met
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        met_smear_tag_data: "xycorr" # useless since that does not run on data, but for consistency
        met_smear_tag: "tes_electron_xycorr" # defines the input smear_tag


####### Creating definitvive pairType (adding MET_pt cut to boostedTaus)
HHLeptonMETCut:
    name: HHLeptonMETCutRDF
    path: Tools.Tools.HHLepton
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        pairType_filter: not self.dataset.process.isSignal
        met_smear_tag_data: "xycorr" # on data only XY corrections are applied to MET, there is no TES or electron S&S
        met_smear_tag: "tes_electron_xycorr"
        useBoostedTaus: self.dataset.process.isMC or not self.dataset.has_tag("hpsData") # don't forget to change this also in hhlepton


########################### FatJet JME corrections 
# we put these corrections here because they do not propagate to MET thus can be put later after filter in hhlepton (processing time optimization)
# same but for FatJet. Actually uses the same correction sources as AK4, but we still need to compute the variations for each AK8 jet
jec_factors_fatjet:
    name: jecProviderRDF
    path: Corrections.JME.jec
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        isUL: self.dataset.has_tag('ul')
        ispreVFP: self.config.get_aux('ispreVFP', False)
        jet_collection: FatJet
jec_fatjet_corrections:
    name: jecVarRDF
    path: Corrections.JME.jec
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        jet_collection: FatJet


# FatJet smearing. Outputs : fatjet_smear_factor (_up/_down) & fatjet_pt_resolution
fatjet_smearing:
    name: jetSmearerRDF
    path: Corrections.JME.smearing
    parameters:
        year: self.config.year
        runPeriod: self.config.runPeriod
        isMC: self.dataset.process.isMC
        isUL: self.dataset.has_tag('ul')
        type: fatjerc
# Create FatJet_pt_nom & FatJet_mass_nom & FatJet_pt_smeared_up/down & FatJet_mass_smeared_up/down
jer_fatjet:
    name: jetVarRDF
    path: Corrections.JME.smearing
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        type: fatjerc


#### HHJets
hhjets:
    name: HHJetsRDF
    path: Tools.Tools.HHJets
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        isUL: self.dataset.has_tag('ul')
        met_smear_tag_data: "xycorr" # on data only XY corrections are applied to MET, there is no TES or electron S&S
        met_smear_tag: "tes_electron_xycorr"
        filter: not self.dataset.process.isSignal
        model_version: 2
        btag_wp: self.config.btag_algo_wps.medium
        fatjet_bbtag_wp: self.config.boosted_bb_tagging_wp
        doGenCutFlow: self.dataset.process.isSignal



bjet1var:
    name: HHJetsVarRDF
    path: Tools.Tools.HHJets
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        variables_withSyst: [pt, mass]
        variables_withoutSyst: [eta, phi, btagDeepFlavB, btagDeepFlavCvL, btagDeepFlavCvB, btagDeepFlavQG, HHbtag]
        index: bjet1_JetIdx
        input_prefix: Jet
        output_prefix: bjet1
bjet2var:
    name: HHJetsVarRDF
    path: Tools.Tools.HHJets
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        variables_withSyst: [pt, mass]
        variables_withoutSyst: [eta, phi, btagDeepFlavB, btagDeepFlavCvL, btagDeepFlavCvB, btagDeepFlavQG, HHbtag]
        index: bjet2_JetIdx
        input_prefix: Jet
        output_prefix: bjet2
fatjetvar:
    name: HHJetsVarRDF
    path: Tools.Tools.HHJets
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        variables_withSyst: [pt, mass]
        variables_withoutSyst: [eta, phi, particleNetLegacy_Xbb, particleNetLegacy_QCD, particleNet_massCorr, tau1, tau2]
        index: fatjet_JetIdx
        input_prefix: FatJet
        output_prefix: fatjet


# # Here we compute a second time the JEC variations for the selected bjets. We could probably reuse the already-computed ones in jec_jet_corrections in some way, should be identitcal
# jecb1:
#     name: jecProviderRDF
#     path: Corrections.JME.jec
#     parameters:
#         year: self.config.year
#         isMC: self.dataset.process.isMC
#         isUL: self.dataset.has_tag('ul')
#         pt: bjet1_pt_nom
#         eta: bjet1_eta
#         mass: bjet1_mass_nom
        
# jecb2:
#     name: jecProviderRDF
#     path: Corrections.JME.jec
#     parameters:
#         year: self.config.year
#         isMC: self.dataset.process.isMC
#         isUL: self.dataset.has_tag('ul')
#         pt: bjet2_pt_nom
#         eta: bjet2_eta
#         mass: bjet2_mass_nom
        
# # same jec variations for fatjet as for AK4
# jecfatjet:
#     name: jecProviderRDF
#     path: Corrections.JME.jec
#     parameters:
#         year: self.config.year
#         isMC: self.dataset.process.isMC
#         isUL: self.dataset.has_tag('ul')
#         pt: fatjet_pt_nom
#         eta: fatjet_eta
#         mass: fatjet_mass_nom
        
# FatJet X->bb tagging scale factors
AK8GenRDF:
    name: AK8GenRDF
    path: Tools.Tools.gen_information
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC

FatJetParticleNetSFProducer:
    name: FatJetParticleNetSFProducerRDF
    path: Tools.Tools.fatjet_pnet_sf
    parameters:
        year: self.config.year
        runPeriod: self.config.runPeriod
        isMC: self.dataset.process.isMC
        dataset: self.dataset.name
        fatjet_bb_type: self.dataset.process.get_aux("fatjet_bb_type")

trigSF:
    name: Htt_trigSFRDF
    path: Tools.Tools.Htt_trigSF
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        isUL: self.dataset.has_tag('ul')
        # only compute systematic for trigger SFs in case we are in "nominal" (we don't apply trigger SFs variations on top of JEC for example)
        computeSystematics_PY: not systematic
        ispreVFP: self.config.get_aux('ispreVFP', False)
        met_smear_tag_data: "xycorr" # on data only XY corrections are applied to MET, there is no TES or electron S&S
        met_smear_tag: "tes_electron_xycorr"

# Computes ['PUjetID_SF', 'PUjetID_SF_up', 'PUjetID_SF_down']
PUjetID_SF:
    name: PUjetID_SFRDF
    path: Corrections.JME.PUjetID_SF
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        isUL: self.dataset.has_tag('ul')
        ispreVFP: self.config.get_aux('ispreVFP', False)
        lep_pt: "{dau1_pt{lep_syst}, dau2_pt{lep_syst}}"
        lep_eta: "{dau1_eta, dau2_eta}"
        lep_phi: "{dau1_phi, dau2_phi}"
        lep_mass: "{dau1_mass{lep_syst}, dau2_mass{lep_syst}}"

muSF:
    name: muSFRDF
    path: Corrections.MUO.muCorrections
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        isUL: self.dataset.has_tag('ul')
        runPeriod: self.config.runPeriod
        wps: ["tight_id", "tight_reliso"]

eleSF:
    name: eleSFRDF
    path: Corrections.EGM.eleCorrections
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        isUL: self.dataset.has_tag('ul')
        runPeriod: self.config.runPeriod
        wps: [wp80iso, Loose, RecoAbove20] # wp80iso for HPSTaus electrons, Loose cut-based for boostedTaus-electrons, Reco for everyone

# Combine electron, muon and tau scale factors. Produces idAndIsoAndFakeSF branches
idAndIsoSF:
    name: dauIdIsoSFRDF
    path: Tools.Tools.dauIdIso
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        runPeriod: self.config.runPeriod
        computeSystematics_PY: not systematic
        # muon_iso_syst_directions: ["_syst_up", "_syst_down"] # syst actually includes stat as well....
        # muon_id_syst_directions: ["_syst_up", "_syst_down"]
        tau_vsjet_pt_syst_directions: "all"
        tau_vsjet_dm_syst_directions: "all"


# ["central", # BTV uncertainties
#             "down_cferr1", "down_cferr2", "down_hf", "down_hfstats1", "down_hfstats2",  "down_lf", "down_lfstats1", "down_lfstats2", 
#             "up_cferr1", "up_cferr2", "up_hf", "up_hfstats1", "up_hfstats2",  "up_lf", "up_lfstats1", "up_lfstats2", 
#             # SFs to be applied on top of the JES variations (reduced set of 11 uncertainties)
#             "down_jesAbsolute", "down_jesFlavorQCD", "down_jesAbsolute_{year}", "down_jesBBEC1", "down_jesBBEC1_{year}", "down_jesEC2", "down_jesEC2_{year}", "down_jesHF", "down_jesHF_{year}", "down_jesRelativeBal", "down_jesRelativeSample", "down_jesRelativeSample_{year}",
#             "up_jesAbsolute", "up_jesFlavorQCD", "up_jesAbsolute_{year}", "up_jesBBEC1", "up_jesBBEC1_{year}", "up_jesEC2", "up_jesEC2_{year}", "up_jesHF", "up_jesHF_{year}", "up_jesRelativeBal", "up_jesRelativeSample", "up_jesRelativeSample_{year}",
#             # one total uncertainty for JES
#             "up_jes", "down_jes"] 
btag:
    name: btag_SFRDF
    path: Corrections.BTV.btag_SF
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        isUL: self.dataset.has_tag('ul')
        ispreVFP: self.config.get_aux('ispreVFP', False)
        # NB: the >- is YAML syntax for multiline string
        reshape_uncertainties_PY: >-
            ["down_jesAbsolute", "down_jesFlavorQCD", "down_jesAbsolute_{year}", "down_jesBBEC1", "down_jesBBEC1_{year}", "down_jesEC2", "down_jesEC2_{year}", "down_jesHF", "down_jesHF_{year}", "down_jesRelativeBal", "down_jesRelativeSample", "down_jesRelativeSample_{year}",
            "up_jesAbsolute", "up_jesFlavorQCD", "up_jesAbsolute_{year}", "up_jesBBEC1", "up_jesBBEC1_{year}", "up_jesEC2", "up_jesEC2_{year}", "up_jesHF", "up_jesHF_{year}", "up_jesRelativeBal", "up_jesRelativeSample", "up_jesRelativeSample_{year}",
            "up_jes", "down_jes"] if "jec" in str(systematic) 
            else 
            ["central"] if systematic
            else
            ["central", 
            "down_cferr1", "down_cferr2", "down_hf", "down_hfstats1", "down_hfstats2",  "down_lf", "down_lfstats1", "down_lfstats2", 
            "up_cferr1", "up_cferr2", "up_hf", "up_hfstats1", "up_hfstats2",  "up_lf", "up_lfstats1", "up_lfstats2"]
        lep_pt: "{dau1_pt{lep_syst}, dau2_pt{lep_syst}}"
        lep_eta: "{dau1_eta, dau2_eta}"
        lep_phi: "{dau1_phi, dau2_phi}"
        lep_mass: "{dau1_mass{lep_syst}, dau2_mass{lep_syst}}"

hemIssue:
    name: hemIssueRDF
    path: Corrections.JME.HEM_issue
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC

puweightCor:
    name: puWeightRDF
    path: Corrections.LUM.puWeightCor
    parameters:
        isMC: self.dataset.process.isMC
        year: self.config.year
        runPeriod: self.config.runPeriod
        isUL: self.dataset.has_tag('ul')

###########
svfit_ZZ:
    name: SVFitRDF
    path: Tools.Tools.svfit
    parameters:
        year: self.config.year
        isMC: self.dataset.process.isMC
        AnalysisType: self.config.get_aux('AnalysisType', False)
        met_smear_tag: "tes_electron_xycorr"
        algo: FastMTT
        
